# Logstash Pipeline Configuration

input {
  # Syslog input for various services
  syslog {
    port => 514
    type => "syslog"
    tags => ["syslog"]
  }

  # Beats input (Filebeat)
  beats {
    port => 5044
    type => "beats"
    tags => ["beats"]
  }

  # JSON input
  tcp {
    port => 5000
    codec => json
    type => "json"
    tags => ["json"]
  }

  # Suricata logs
  file {
    path => "/var/log/suricata/eve.json"
    codec => json
    type => "suricata"
    tags => ["ids", "suricata"]
  }
}

filter {
  # Parse syslog messages
  if "syslog" in [tags] {
    grok {
      match => { "message" => "%{SYSLOGBASE} %{GREEDYDATA:syslog_message}" }
    }

    date {
      match => [ "timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }

  # Process Suricata IDS logs
  if [type] == "suricata" {
    # Add GeoIP information for source IPs
    if [src_ip] {
      geoip {
        source => "src_ip"
        target => "geoip_src"
      }
    }

    if [dest_ip] {
      geoip {
        source => "dest_ip"
        target => "geoip_dest"
      }
    }

    # Categorize by event type
    if [event_type] == "alert" {
      mutate {
        add_field => { "severity" => "high" }
        add_tag => [ "security_alert" ]
      }
    }
  }

  # Parse nginx logs
  if [tags] and "nginx" in [tags] {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }

    # Detect suspicious patterns
    if [request] =~ /(\.\.|<script|SELECT.*FROM|UNION.*SELECT)/ {
      mutate {
        add_tag => [ "suspicious", "potential_attack" ]
        add_field => { "threat_type" => "web_attack" }
      }
    }
  }

  # Parse PostgreSQL logs
  if [tags] and "postgresql" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:pid}\] %{WORD:log_level}: %{GREEDYDATA:pg_message}" }
    }

    if [pg_message] =~ /(FATAL|ERROR)/ {
      mutate {
        add_tag => [ "database_error" ]
      }
    }
  }

  # Enrich with timestamp
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }

  # Add environment metadata
  mutate {
    add_field => {
      "environment" => "cyberlab"
      "log_source" => "docker"
    }
  }

  # Remove empty fields
  prune {
    whitelist_names => [ "^@", "^timestamp", "^message", "^host", "^severity", "^event_type", "^src_ip", "^dest_ip", "^alert" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "${ELASTICSEARCH_PASSWORD}"
    index => "logstash-%{type}-%{+YYYY.MM.dd}"
    manage_template => true
  }

  # High-severity alerts to separate index
  if [severity] == "high" or "security_alert" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      user => "elastic"
      password => "${ELASTICSEARCH_PASSWORD}"
      index => "security-alerts-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (optional, remove in production)
  # stdout {
  #   codec => rubydebug
  # }
}
