version: "3.8"

networks:
  external_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/24
          gateway: 172.25.0.1

  dmz_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.10.0/24
          gateway: 172.25.10.1

  internal_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.20.0/24
          gateway: 172.25.20.1

  security_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.30.0/24
          gateway: 172.25.30.1

  management_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.40.0/24
          gateway: 172.25.40.1

volumes:
  #Wazuh volumes
  wazuh_api_configuration:
  wazuh_etc:
  wazuh_logs:
  wazuh_queue:
  wazuh_var_multigroups:
  wazuh_integrations:
  wazuh_active_response:
  wazuh_agentless:
  wazuh_wodles:
  filebeat_etc:
  filebeat_var:
  wazuh-indexer-data:
  wazuh-dashboard-config:
  wazuh-dashboard-custom:

  postgres_data:
  openldap_data:
  openldap_config:
  radius_data:
  nginx_certs:
  neuvector_controller:
  neuvector_consul:
  grafana_data:
  prometheus_data:
  rocketchat_data:
  thehive_data:
  cortex_data:
  backup_data:
  suricata_logs:
  suricata_rules:
  tpot_data:
  # ollama_data:

services:
  # ============================================================================
  # NETWORK & FIREWALL LAYER
  # ============================================================================

  # Consul - Service discovery for NeuVector clustering (must start first)
  consul:
    image: hashicorp/consul:1.17
    container_name: consul
    hostname: consul
    networks:
      security_net:
        ipv4_address: 172.25.30.6
    command: agent -server -ui -bootstrap-expect=1 -client=0.0.0.0
    environment:
      - CONSUL_BIND_INTERFACE=eth0
      - TZ=UTC
    volumes:
      - neuvector_consul:/consul/data
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.3

  # NeuVector Controller - Main control center
  neuvector-controller:
    image: neuvector/controller:latest
    container_name: neuvector-controller
    hostname: neuvector-controller
    privileged: true
    networks:
      external_net:
        ipv4_address: 172.25.0.10
      dmz_net:
        ipv4_address: 172.25.10.254
      internal_net:
        ipv4_address: 172.25.20.254
      security_net:
        ipv4_address: 172.25.30.254
    environment:
      - CLUSTER_JOIN_ADDR=172.25.30.6
      - CONSUL_ADDR=http://consul:8500
      - CTRL_PERSIST_CONFIG=1
      - TZ=UTC
    volumes:
      - neuvector_controller:/var/neuvector
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./configs/neuvector/certs:/etc/neuvector/certs:ro
    depends_on:
      - consul
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.0

  # NeuVector Enforcer - Network policy enforcement
  neuvector-enforcer:
    image: neuvector/enforcer:latest
    container_name: neuvector-enforcer
    hostname: neuvector-enforcer
    privileged: true
    pid: host
    networks:
      external_net:
        ipv4_address: 172.25.0.12
      dmz_net:
        ipv4_address: 172.25.10.253
      internal_net:
        ipv4_address: 172.25.20.253
      security_net:
        ipv4_address: 172.25.30.253
    environment:
      - CLUSTER_JOIN_ADDR=172.25.30.6
      - CONSUL_ADDR=http://172.25.30.6:8500
      - TZ=UTC
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc:/host/proc:ro
      - /sys/fs/cgroup:/host/cgroup:ro
      - /var/neuvector:/var/neuvector
    depends_on:
      - consul
      - neuvector-controller
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5

  # NeuVector Manager - Web UI
  neuvector-manager:
    image: neuvector/manager:latest
    container_name: neuvector-manager
    hostname: neuvector-manager
    networks:
      external_net:
        ipv4_address: 172.25.0.11
    ports:
      - "8443:8443" # Web UI (HTTPS)
    environment:
      - TZ=UTC
    depends_on:
      - neuvector-controller
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5

  # NeuVector Scanner - Vulnerability scanning
  neuvector-scanner:
    image: neuvector/scanner:latest
    container_name: neuvector-scanner
    hostname: neuvector-scanner
    networks:
      security_net:
        ipv4_address: 172.25.30.5
    environment:
      - CLUSTER_JOIN_ADDR=172.25.30.6
      - CONSUL_ADDR=http://172.25.30.6:8500
      - TZ=UTC
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - consul
      - neuvector-controller
    restart: unless-stopped
    mem_limit: 1.5g
    cpus: 0.5

  # VPN Gateway - WireGuard
  wireguard:
    image: linuxserver/wireguard:latest
    container_name: wireguard
    hostname: wireguard
    networks:
      external_net:
        ipv4_address: 172.25.0.20
    ports:
      - "51820:51820/udp"
    volumes:
      - ./configs/wireguard:/config
      - /lib/modules:/lib/modules
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=UTC
      - PEERS=10
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5

  # VPN Gateway - OpenVPN (legacy support)
  # openvpn:
  #   image: kylemanna/openvpn:latest
  #   container_name: openvpn
  #   hostname: openvpn
  #   networks:
  #     external_net:
  #       ipv4_address: 172.25.0.21
  #   ports:
  #     - "1194:1194/udp"
  #   volumes:
  #     - ./configs/openvpn:/etc/openvpn
  #   cap_add:
  #     - NET_ADMIN
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.3

  # ============================================================================
  # DMZ LAYER - PUBLIC FACING SERVICES
  # ============================================================================

  nginx:
    image: nginx:alpine
    container_name: nginx
    hostname: nginx
    networks:
      dmz_net:
        ipv4_address: 172.25.10.10
      internal_net:
        ipv4_address: 172.25.20.10
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./configs/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./configs/nginx/conf.d:/etc/nginx/conf.d:ro
      - nginx_certs:/etc/nginx/certs
      - ./web:/usr/share/nginx/html
    environment:
      - TZ=UTC
    depends_on:
      - neuvector-controller
      - wazuh.manager
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: syslog
      options:
        syslog-address: "udp://172.25.30.20:514"
        tag: "nginx"

  # Honeypot - T-Pot
  # use https://github.com/telekom-security/tpotce for more details
  # tpot:
  # image: telekom/tpotce:latest
  # container_name: tpot
  # hostname: tpot
  # networks:
  #   dmz_net:
  #     ipv4_address: 172.25.10.50
  # ports:
  #   - "64295:64295" # SSH
  #   - "64297:64297" # Web UI
  # volumes:
  #   - tpot_data:/data
  #   - ./configs/tpot:/opt/tpot/etc/compose
  # environment:
  #   - TZ=UTC
  # restart: unless-stopped
  # mem_limit: 2g
  # cpus: 0.5
  # logging:
  #   driver: syslog
  #   options:
  #     syslog-address: "udp://172.25.30.30:514"
  #     tag: "tpot"

  # ============================================================================
  # INTERNAL NETWORK - PROTECTED SERVICES
  # ============================================================================

  postgresql:
    image: postgres:15-alpine
    container_name: postgresql
    hostname: postgresql
    networks:
      internal_net:
        ipv4_address: 172.25.20.30
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-SecureP@ssw0rd}
      - POSTGRES_USER=postgres
      - POSTGRES_MULTIPLE_DATABASES=wazuh,thehive,cortex,rocketchat
      - TZ=UTC
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh
    depends_on:
      - wazuh.manager
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5
    logging:
      driver: syslog
      options:
        syslog-address: "udp://172.25.30.20:514"
        tag: "postgresql"

  # OpenLDAP
  openldap:
    image: osixia/openldap:latest
    container_name: openldap
    hostname: openldap
    networks:
      internal_net:
        ipv4_address: 172.25.20.40
    environment:
      - LDAP_ORGANISATION=${LDAP_ORGANISATION:-CyberLab}
      - LDAP_DOMAIN=${LDAP_DOMAIN:-cyberlab.local}
      - LDAP_ADMIN_PASSWORD=${LDAP_ADMIN_PASSWORD:-admin}
      - LDAP_CONFIG_PASSWORD=${LDAP_CONFIG_PASSWORD:-config}
      - LDAP_TLS=true
      - LDAP_TLS_VERIFY_CLIENT=try
    volumes:
      - openldap_data:/var/lib/ldap
      - openldap_config:/etc/ldap/slapd.d
      - ./configs/ldap/certs:/container/service/slapd/assets/certs
    ports:
      - "389:389"
      - "636:636"
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.3

  # LDAP Admin UI
  phpldapadmin:
    image: osixia/phpldapadmin:latest
    container_name: phpldapadmin
    hostname: phpldapadmin
    networks:
      internal_net:
        ipv4_address: 172.25.20.41
    environment:
      - PHPLDAPADMIN_LDAP_HOSTS=openldap
      - PHPLDAPADMIN_HTTPS=false
    ports:
      - "6443:443"
    depends_on:
      - openldap
    restart: unless-stopped
    mem_limit: 256m
    cpus: 0.2

  # Rocket.Chat (Communication)
  # rocketchat:
  #   image: rocket.chat:latest
  #   container_name: rocketchat
  #   hostname: rocketchat
  #   networks:
  #     internal_net:
  #       ipv4_address: 172.25.20.50
  #   environment:
  #     - MONGO_URL=mongodb://mongodb:27017/rocketchat
  #     - MONGO_OPLOG_URL=mongodb://mongodb:27017/local
  #     - ROOT_URL=http://localhost:3100
  #     - PORT=3000
  #     - ADMIN_USERNAME=admin
  #     - ADMIN_PASS=${ROCKETCHAT_PASSWORD:-admin}
  #     - ADMIN_EMAIL=admin@cyberlab.local
  #   ports:
  #     - "3100:3000"
  #   depends_on:
  #     - mongodb
  #   restart: unless-stopped
  #   mem_limit: 1g
  #   cpus: 0.5

  # mongodb:
  #   image: mongo:5
  #   container_name: mongodb
  #   hostname: mongodb
  #   networks:
  #     internal_net:
  #       ipv4_address: 172.25.20.51
  #   volumes:
  #     - rocketchat_data:/data/db
  #   command: mongod --oplogSize 128 --replSet rs0
  #   restart: unless-stopped
  #   mem_limit: 1g
  #   cpus: 0.3

  # ============================================================================
  # SECURITY NETWORK - MONITORING & DEFENSE
  # ============================================================================

  # Wazuh Indexer (OpenSearch-based) - Must start first
  wazuh.indexer:
    image: wazuh/wazuh-indexer:4.14.0
    container_name: wazuh.indexer
    hostname: wazuh.indexer
    restart: always
    networks:
      security_net:
        ipv4_address: 172.25.30.10
    ports:
      - "9200:9200"
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g"
      - TZ=UTC
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - wazuh-indexer-data:/var/lib/wazuh-indexer
      - ./configs/wazuh/wazuh_indexer_ssl_certs/root-ca.pem:/usr/share/wazuh-indexer/config/certs/root-ca.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.indexer-key.pem:/usr/share/wazuh-indexer/config/certs/wazuh.indexer.key
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.indexer.pem:/usr/share/wazuh-indexer/config/certs/wazuh.indexer.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/admin.pem:/usr/share/wazuh-indexer/config/certs/admin.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/admin-key.pem:/usr/share/wazuh-indexer/config/certs/admin-key.pem
      - ./configs/wazuh/wazuh_indexer/wazuh.indexer.yml:/usr/share/wazuh-indexer/config/opensearch.yml
      - ./configs/wazuh/wazuh_indexer/internal_users.yml:/usr/share/wazuh-indexer/config/opensearch-security/internal_users.yml
    mem_limit: 2g
    cpus: 1.0

  # Wazuh Manager - Starts after indexer
  wazuh.manager:
    image: wazuh/wazuh-manager:4.14.0
    container_name: wazuh.manager
    hostname: wazuh.manager
    restart: always
    networks:
      security_net:
        ipv4_address: 172.25.30.20
      internal_net:
        ipv4_address: 172.25.20.60
      dmz_net:
        ipv4_address: 172.25.10.60
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 655360
        hard: 655360
    ports:
      - "1514:1514" # Agent events
      - "1515:1515" # Agent enrollment
      - "514:514/udp" # Syslog
      - "55000:55000" # API
    environment:
      - INDEXER_URL=https://wazuh.indexer:9200
      - INDEXER_USERNAME=admin
      - INDEXER_PASSWORD=SecretPassword
      - FILEBEAT_SSL_VERIFICATION_MODE=full
      - SSL_CERTIFICATE_AUTHORITIES=/etc/ssl/root-ca.pem
      - SSL_CERTIFICATE=/etc/ssl/filebeat.pem
      - SSL_KEY=/etc/ssl/filebeat.key
      - API_USERNAME=wazuh-wui
      - API_PASSWORD=MyS3cr37P450r.*-
      - TZ=UTC
    volumes:
      - wazuh_api_configuration:/var/ossec/api/configuration
      - wazuh_etc:/var/ossec/etc
      - wazuh_logs:/var/ossec/logs
      - wazuh_queue:/var/ossec/queue
      - wazuh_var_multigroups:/var/ossec/var/multigroups
      - wazuh_integrations:/var/ossec/integrations
      - wazuh_active_response:/var/ossec/active-response/bin
      - wazuh_agentless:/var/ossec/agentless
      - wazuh_wodles:/var/ossec/wodles
      - filebeat_etc:/etc/filebeat
      - filebeat_var:/var/lib/filebeat
      - ./configs/wazuh/wazuh_indexer_ssl_certs/root-ca-manager.pem:/etc/ssl/root-ca.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.manager.pem:/etc/ssl/filebeat.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.manager-key.pem:/etc/ssl/filebeat.key
      - ./configs/wazuh/wazuh_cluster/wazuh_manager.conf:/wazuh-config-mount/etc/ossec.conf
    depends_on:
      - wazuh.indexer
    mem_limit: 2g
    cpus: 1.0

  # Wazuh Dashboard - Starts after manager and indexer
  wazuh.dashboard:
    image: wazuh/wazuh-dashboard:4.14.0
    container_name: wazuh.dashboard
    hostname: wazuh.dashboard
    restart: always
    networks:
      security_net:
        ipv4_address: 172.25.30.21
    ports:
      - "5601:5601"
    environment:
      - INDEXER_USERNAME=admin
      - INDEXER_PASSWORD=SecretPassword
      - WAZUH_API_URL=https://wazuh.manager
      - DASHBOARD_USERNAME=kibanaserver
      - DASHBOARD_PASSWORD=kibanaserver
      - API_USERNAME=wazuh-wui
      - API_PASSWORD=MyS3cr37P450r.*-
      - TZ=UTC
    volumes:
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.dashboard.pem:/usr/share/wazuh-dashboard/certs/wazuh-dashboard.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/wazuh.dashboard-key.pem:/usr/share/wazuh-dashboard/certs/wazuh-dashboard-key.pem
      - ./configs/wazuh/wazuh_indexer_ssl_certs/root-ca.pem:/usr/share/wazuh-dashboard/certs/root-ca.pem
      - ./configs/wazuh/wazuh_dashboard/opensearch_dashboards.yml:/usr/share/wazuh-dashboard/config/opensearch_dashboards.yml
      - ./configs/wazuh/wazuh_dashboard/wazuh.yml:/usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml
      - wazuh-dashboard-config:/usr/share/wazuh-dashboard/data/wazuh/config
      - wazuh-dashboard-custom:/usr/share/wazuh-dashboard/plugins/wazuh/public/assets/custom
    depends_on:
      - wazuh.indexer
      - wazuh.manager
    links:
      - wazuh.indexer:wazuh.indexer
      - wazuh.manager:wazuh.manager
    mem_limit: 1g
    cpus: 0.5

  # NOTE: Filebeat is built into wazuh.manager container - no separate service needed
  # NOTE: Elasticsearch is replaced by wazuh.indexer (OpenSearch-based)
  # NOTE: Kibana is replaced by wazuh.dashboard

  # Suricata - IDS/IPS
  suricata:
    image: jasonish/suricata:latest
    container_name: suricata
    hostname: suricata
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_NICE
    volumes:
      - suricata_logs:/var/log/suricata
      - suricata_rules:/var/lib/suricata
      - ./configs/suricata/suricata.yaml:/etc/suricata/suricata.yaml
    command: -i eth0
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.0

  # TheHive - Incident Response Platform
  # Note: TheHive can use wazuh.indexer (OpenSearch) as its database
  # thehive:
  #   image: strangebee/thehive:5.2
  #   container_name: thehive
  #   hostname: thehive
  #   networks:
  #     security_net:
  #       ipv4_address: 172.25.30.40
  #   environment:
  #     - JVM_OPTS=-Xms1g -Xmx1g
  #   volumes:
  #     - thehive_data:/opt/thp/thehive/data
  #     - ./configs/thehive/application.conf:/etc/thehive/application.conf
  #   ports:
  #     - "9000:9000"
  #   depends_on:
  #     - wazuh.indexer
  #     - wazuh.manager
  #   restart: unless-stopped
  #   mem_limit: 1.5g
  #   cpus: 0.5
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "thehive"

  # Cortex - TheHive Analysis Engine
  # cortex:
  #   image: thehiveproject/cortex:latest
  #   container_name: cortex
  #   hostname: cortex
  #   networks:
  #     security_net:
  #       ipv4_address: 172.25.30.41
  #   environment:
  #     - job_directory=/tmp/cortex-jobs
  #   volumes:
  #     - cortex_data:/var/cortex
  #     - ./configs/cortex/application.conf:/etc/cortex/application.conf
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   ports:
  #     - "9001:9001"
  #   depends_on:
  #     - wazuh.indexer
  #     - wazuh.manager
  #   restart: unless-stopped
  #   mem_limit: 1g
  #   cpus: 0.3
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "cortex"

  # AI Log Analyzer - Custom Service
  # Note: Uses Wazuh indexer (OpenSearch) instead of Elasticsearch
  # ai-analyzer:
  #   build:
  #     context: ./ai-analyzer
  #     dockerfile: Dockerfile
  #   container_name: ai-analyzer
  #   hostname: ai-analyzer
  #   networks:
  #     security_net:
  #       ipv4_address: 172.25.30.50
  #   environment:
  #     - OPENSEARCH_HOST=https://wazuh.indexer:9200
  #     - OPENSEARCH_USER=admin
  #     - OPENSEARCH_PASSWORD=SecretPassword
  #     - OLLAMA_HOST=http://ollama:11434
  #     - WAZUH_API_URL=https://wazuh.manager:55000
  #     - WAZUH_API_USER=wazuh-wui
  #     - WAZUH_API_PASSWORD=MyS3cr37P450r.*-
  #     - ALERT_WEBHOOK=${ROCKETCHAT_WEBHOOK_URL:-}
  #   volumes:
  #     - ./ai-analyzer:/app
  #     - ollama_data:/root/.ollama
  #   depends_on:
  #     - wazuh.indexer
  #     - wazuh.manager
  #     - ollama
  #   restart: unless-stopped
  #   mem_limit: 2g
  #   cpus: 0.5
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "ai-analyzer"

  # Ollama - Local LLM
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   hostname: ollama
  #   networks:
  #     security_net:
  #       ipv4_address: 172.25.30.51
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   restart: unless-stopped
  #   mem_limit: 4g
  #   cpus: 1.0

  # ============================================================================
  # MANAGEMENT NETWORK - MONITORING & ADMINISTRATION
  # ============================================================================

  # Prometheus - Metrics Collection
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   hostname: prometheus
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.10
  #     security_net:
  #       ipv4_address: 172.25.30.60
  #   volumes:
  #     - prometheus_data:/prometheus
  #     - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #     - ./configs/prometheus/alerts:/etc/prometheus/alerts:ro
  #   command:
  #     - "--config.file=/etc/prometheus/prometheus.yml"
  #     - "--storage.tsdb.path=/prometheus"
  #     - "--web.console.libraries=/usr/share/prometheus/console_libraries"
  #     - "--web.console.templates=/usr/share/prometheus/consoles"
  #   ports:
  #     - "9090:9090"
  #   depends_on:
  #     - wazuh.manager
  #   restart: unless-stopped
  #   mem_limit: 1g
  #   cpus: 0.3
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "prometheus"

  # # Grafana - Monitoring Dashboard
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: grafana
  #   hostname: grafana
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.11
  #   environment:
  #     - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
  #     - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
  #     - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
  #     - GF_SERVER_ROOT_URL=http://localhost:3000
  #     - GF_AUTH_LDAP_ENABLED=true
  #     - GF_AUTH_LDAP_CONFIG_FILE=/etc/grafana/ldap.toml
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #     - ./configs/grafana/grafana.ini:/etc/grafana/grafana.ini
  #     - ./configs/grafana/ldap.toml:/etc/grafana/ldap.toml
  #     - ./dashboards:/etc/grafana/provisioning/dashboards
  #   ports:
  #     - "3000:3000"
  #   depends_on:
  #     - prometheus
  #     - openldap
  #     - wazuh.manager
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.3
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "grafana"

  # # FreeRADIUS - AAA Server
  # freeradius:
  #   image: freeradius/freeradius-server:latest
  #   container_name: freeradius
  #   hostname: freeradius
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.20
  #     internal_net:
  #       ipv4_address: 172.25.20.70
  #   environment:
  #     - RADIUS_LDAP_SERVER=openldap
  #     - RADIUS_LDAP_BASE_DN=dc=cyberlab,dc=local
  #     - RADIUS_LDAP_BIND_DN=cn=admin,dc=cyberlab,dc=local
  #     - RADIUS_LDAP_BIND_PASSWORD=${LDAP_ADMIN_PASSWORD:-admin}
  #   volumes:
  #     - radius_data:/etc/raddb
  #     - ./configs/radius:/config
  #   ports:
  #     - "1812:1812/udp" # Authentication
  #     - "1813:1813/udp" # Accounting
  #   depends_on:
  #     - openldap
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.2

  # # Backup Service
  # backup:
  #   image: restic/restic:latest
  #   container_name: backup
  #   hostname: backup
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.30
  #   environment:
  #     - RESTIC_REPOSITORY=/backup-repo
  #     - RESTIC_PASSWORD=${BACKUP_PASSWORD:-SecureBackupP@ss}
  #     - BACKUP_SCHEDULE=0 2 * * *
  #   volumes:
  #     - backup_data:/backup-repo
  #     - wazuh-indexer-data:/backup-source/wazuh-indexer:ro
  #     - postgres_data:/backup-source/postgres:ro
  #     - openldap_data:/backup-source/ldap:ro
  #     - wazuh_etc:/backup-source/wazuh:ro
  #     - ./configs:/backup-source/configs:ro
  #     - ./scripts/backup.sh:/usr/local/bin/backup.sh:ro
  #   command: sh -c "chmod +x /usr/local/bin/backup.sh && /usr/local/bin/backup.sh"
  #   depends_on:
  #     - wazuh.manager
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.2
  #   logging:
  #     driver: syslog
  #     options:
  #       syslog-address: "udp://172.25.30.20:514"
  #       tag: "backup"

  # # Node Exporter - System Metrics
  # node-exporter:
  #   image: prom/node-exporter:latest
  #   container_name: node-exporter
  #   hostname: node-exporter
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.40
  #   command:
  #     - "--path.procfs=/host/proc"
  #     - "--path.sysfs=/host/sys"
  #     - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
  #   volumes:
  #     - /proc:/host/proc:ro
  #     - /sys:/host/sys:ro
  #     - /:/rootfs:ro
  #   ports:
  #     - "9100:9100"
  #   restart: unless-stopped
  #   mem_limit: 256m
  #   cpus: 0.1

  # # cAdvisor - Container Metrics
  # cadvisor:
  #   image: gcr.io/cadvisor/cadvisor:latest
  #   container_name: cadvisor
  #   hostname: cadvisor
  #   networks:
  #     management_net:
  #       ipv4_address: 172.25.40.41
  #   volumes:
  #     - /:/rootfs:ro
  #     - /var/run:/var/run:ro
  #     - /sys:/sys:ro
  #     - /var/lib/docker:/var/lib/docker:ro
  #     - /dev/disk:/dev/disk:ro
  #   ports:
  #     - "8081:8080"
  #   privileged: true
  #   devices:
  #     - /dev/kmsg
  #   restart: unless-stopped
  #   mem_limit: 256m
  #   cpus: 0.1
