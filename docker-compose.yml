version: "3.8"

networks:
  external_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
          gateway: 172.20.0.1

  dmz_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.10.0/24
          gateway: 172.20.10.1

  internal_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.20.0/24
          gateway: 172.20.20.1

  security_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.30.0/24
          gateway: 172.20.30.1

  management_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.40.0/24
          gateway: 172.20.40.1

volumes:
  elasticsearch_data:
  wazuh_api_configuration:
  wazuh_etc:
  wazuh_logs:
  wazuh_queue:
  wazuh_var_multigroups:
  wazuh_integrations:
  wazuh_active_response:
  wazuh_agentless:
  wazuh_wodles:
  # filebeat_etc:
  # filebeat_var:
  postgres_data:
  openldap_data:
  openldap_config:
  radius_data:
  nginx_certs:
  opnsense_config:
  grafana_data:
  prometheus_data:
  rocketchat_data:
  thehive_data:
  cortex_data:
  backup_data:
  suricata_logs:
  suricata_rules:
  tpot_data:
  # ollama_data:

services:
  # ============================================================================
  # NETWORK & FIREWALL LAYER
  # ============================================================================

  opnsense:
    image: demisto/opnsense:1.0.0.4889421
    container_name: opnsense
    hostname: opnsense
    privileged: true
    networks:
      external_net:
        ipv4_address: 172.20.0.10
      dmz_net:
        ipv4_address: 172.20.10.1
      internal_net:
        ipv4_address: 172.20.20.1
      security_net:
        ipv4_address: 172.20.30.1
    ports:
      - "8443:443" # Web UI
      - "8080:80" # HTTP redirect
    volumes:
      - opnsense_config:/conf
      - ./configs/opnsense:/usr/local/etc/opnsense
    environment:
      - TZ=UTC
    cap_add:
      - NET_ADMIN
      - NET_RAW
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.0

  # VPN Gateway - WireGuard
  wireguard:
    image: linuxserver/wireguard:latest
    container_name: wireguard
    hostname: wireguard
    networks:
      external_net:
        ipv4_address: 172.20.0.20
    ports:
      - "51820:51820/udp"
    volumes:
      - ./configs/wireguard:/config
      - /lib/modules:/lib/modules
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=UTC
      - PEERS=10
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5

  # VPN Gateway - OpenVPN (legacy support)
  # openvpn:
  #   image: kylemanna/openvpn:latest
  #   container_name: openvpn
  #   hostname: openvpn
  #   networks:
  #     external_net:
  #       ipv4_address: 172.20.0.21
  #   ports:
  #     - "1194:1194/udp"
  #   volumes:
  #     - ./configs/openvpn:/etc/openvpn
  #   cap_add:
  #     - NET_ADMIN
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.3

  # ============================================================================
  # DMZ LAYER - PUBLIC FACING SERVICES
  # ============================================================================

  nginx:
    image: nginx:alpine
    container_name: nginx
    hostname: nginx
    networks:
      dmz_net:
        ipv4_address: 172.20.10.10
      internal_net:
        ipv4_address: 172.20.20.10
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./configs/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./configs/nginx/conf.d:/etc/nginx/conf.d:ro
      - nginx_certs:/etc/nginx/certs
      - ./web:/usr/share/nginx/html
    environment:
      - TZ=UTC
    depends_on:
      - opnsense
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: syslog
      options:
        syslog-address: "udp://172.20.30.30:514"
        tag: "nginx"

  # Honeypot - T-Pot
  # use https://github.com/telekom-security/tpotce for more details
  # tpot:
  # image: telekom/tpotce:latest
  # container_name: tpot
  # hostname: tpot
  # networks:
  #   dmz_net:
  #     ipv4_address: 172.20.10.50
  # ports:
  #   - "64295:64295" # SSH
  #   - "64297:64297" # Web UI
  # volumes:
  #   - tpot_data:/data
  #   - ./configs/tpot:/opt/tpot/etc/compose
  # environment:
  #   - TZ=UTC
  # restart: unless-stopped
  # mem_limit: 2g
  # cpus: 0.5
  # logging:
  #   driver: syslog
  #   options:
  #     syslog-address: "udp://172.20.30.30:514"
  #     tag: "tpot"

  # ============================================================================
  # INTERNAL NETWORK - PROTECTED SERVICES
  # ============================================================================

  postgresql:
    image: postgres:15-alpine
    container_name: postgresql
    hostname: postgresql
    networks:
      internal_net:
        ipv4_address: 172.20.20.30
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-SecureP@ssw0rd}
      - POSTGRES_USER=postgres
      - POSTGRES_MULTIPLE_DATABASES=wazuh,thehive,cortex,rocketchat
      - TZ=UTC
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5
    logging:
      driver: syslog
      options:
        syslog-address: "udp://172.20.30.30:514"
        tag: "postgresql"

  # OpenLDAP
  openldap:
    image: osixia/openldap:latest
    container_name: openldap
    hostname: openldap
    networks:
      internal_net:
        ipv4_address: 172.20.20.40
    environment:
      - LDAP_ORGANISATION=${LDAP_ORGANISATION:-CyberLab}
      - LDAP_DOMAIN=${LDAP_DOMAIN:-cyberlab.local}
      - LDAP_ADMIN_PASSWORD=${LDAP_ADMIN_PASSWORD:-admin}
      - LDAP_CONFIG_PASSWORD=${LDAP_CONFIG_PASSWORD:-config}
      - LDAP_TLS=true
      - LDAP_TLS_VERIFY_CLIENT=try
    volumes:
      - openldap_data:/var/lib/ldap
      - openldap_config:/etc/ldap/slapd.d
      - ./configs/ldap/certs:/container/service/slapd/assets/certs
    ports:
      - "389:389"
      - "636:636"
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.3

  # LDAP Admin UI
  phpldapadmin:
    image: osixia/phpldapadmin:latest
    container_name: phpldapadmin
    hostname: phpldapadmin
    networks:
      internal_net:
        ipv4_address: 172.20.20.41
    environment:
      - PHPLDAPADMIN_LDAP_HOSTS=openldap
      - PHPLDAPADMIN_HTTPS=false
    ports:
      - "6443:443"
    depends_on:
      - openldap
    restart: unless-stopped
    mem_limit: 256m
    cpus: 0.2

  # Rocket.Chat (Communication)
  rocketchat:
    image: rocket.chat:latest
    container_name: rocketchat
    hostname: rocketchat
    networks:
      internal_net:
        ipv4_address: 172.20.20.50
    environment:
      - MONGO_URL=mongodb://mongodb:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongodb:27017/local
      - ROOT_URL=http://localhost:3100
      - PORT=3000
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=${ROCKETCHAT_PASSWORD:-admin}
      - ADMIN_EMAIL=admin@cyberlab.local
    ports:
      - "3100:3000"
    depends_on:
      - mongodb
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5

  mongodb:
    image: mongo:5
    container_name: mongodb
    hostname: mongodb
    networks:
      internal_net:
        ipv4_address: 172.20.20.51
    volumes:
      - rocketchat_data:/data/db
    command: mongod --oplogSize 128 --replSet rs0
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.3

  # ============================================================================
  # SECURITY NETWORK - MONITORING & DEFENSE
  # ============================================================================

  # Elasticsearch - SIEM Backend
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    hostname: elasticsearch
    networks:
      security_net:
        ipv4_address: 172.20.30.10
    environment:
      - node.name=elasticsearch
      - cluster.name=cyberlab-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-changeme}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./configs/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9200:9200"
    restart: unless-stopped
    mem_limit: 4g
    cpus: 1.0

  # # Kibana - SIEM Visualization
  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.11.0
  #   container_name: kibana
  #   hostname: kibana
  #   networks:
  #     security_net:
  #       ipv4_address: 172.20.30.11
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #     - ELASTICSEARCH_USERNAME=elastic
  #     - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD:-changeme}
  #     - SERVER_NAME=kibana
  #     - SERVER_HOST=0.0.0.0
  #   volumes:
  #     - ./configs/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
  #   ports:
  #     - "5601:5601"
  #   depends_on:
  #     - elasticsearch
  #   restart: unless-stopped
  #   mem_limit: 1g
  #   cpus: 0.5

  # Wazuh Manager
  wazuh:
    image: wazuh/wazuh-manager:4.7.0
    container_name: wazuh
    hostname: wazuh-manager
    networks:
      security_net:
        ipv4_address: 172.20.30.20
      internal_net:
        ipv4_address: 172.20.20.60
    environment:
      - INDEXER_URL=https://elasticsearch:9200
      - INDEXER_USERNAME=admin
      - INDEXER_PASSWORD=${ELASTIC_PASSWORD:-changeme}
      - FILEBEAT_SSL_VERIFICATION_MODE=none
      - SSL_CERTIFICATE_AUTHORITIES=/etc/ssl/root-ca.pem
      - SSL_CERTIFICATE=/etc/ssl/filebeat.pem
      - SSL_KEY=/etc/ssl/filebeat.key
      - API_USERNAME=wazuh-wui
      - API_PASSWORD=${WAZUH_API_PASSWORD:-MyS3cr37P450r.*-}
    volumes:
      - wazuh_api_configuration:/var/ossec/api/configuration
      - wazuh_etc:/var/ossec/etc
      - wazuh_logs:/var/ossec/logs
      - wazuh_queue:/var/ossec/queue
      - wazuh_var_multigroups:/var/ossec/var/multigroups
      - wazuh_integrations:/var/ossec/integrations
      - wazuh_active_response:/var/ossec/active-response/bin
      - wazuh_agentless:/var/ossec/agentless
      - wazuh_wodles:/var/ossec/wodles
      - ./configs/wazuh:/wazuh-config-mount
    ports:
      - "1514:1514" # Agent connection
      - "1515:1515" # Agent enrollment
      - "514:514/udp" # Syslog
      - "55000:55000" # API
    restart: unless-stopped
    mem_limit: 2g
    cpus: 0.5

  # Wazuh Dashboard
  wazuh-dashboard:
    image: wazuh/wazuh-dashboard:4.7.0
    container_name: wazuh-dashboard
    hostname: wazuh-dashboard
    networks:
      security_net:
        ipv4_address: 172.20.30.21
    environment:
      - INDEXER_USERNAME=admin
      - INDEXER_PASSWORD=${ELASTIC_PASSWORD:-changeme}
      - WAZUH_API_URL=https://wazuh:55000
      - DASHBOARD_USERNAME=kibanaserver
      - DASHBOARD_PASSWORD=${WAZUH_DASHBOARD_PASSWORD:-kibanaserver}
      - API_USERNAME=wazuh-wui
      - API_PASSWORD=${WAZUH_API_PASSWORD:-MyS3cr37P450r.*-}
    ports:
      - "5602:5601"
    depends_on:
      - wazuh
      - elasticsearch
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.3

  # Filebeat - Log Shipper
  # filebeat:
  #   image: docker.elastic.co/beats/filebeat:8.11.0
  #   container_name: filebeat
  #   hostname: filebeat
  #   user: root
  #   networks:
  #     security_net:
  #       ipv4_address: 172.20.30.22
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #     - ELASTICSEARCH_USERNAME=elastic
  #     - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD:-changeme}
  #     - KIBANA_HOST=http://kibana:5601
  #   volumes:
  #     - filebeat_etc:/usr/share/filebeat
  #     - filebeat_var:/var/lib/filebeat
  #     - ./configs/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #   command: filebeat -e -strict.perms=false
  #   depends_on:
  #     - elasticsearch
  #     - kibana
  #   restart: unless-stopped
  #   mem_limit: 512m
  #   cpus: 0.3

  # Logstash - Log Processing
  # logstash:
  #   image: docker.elastic.co/logstash/logstash:8.11.0
  #   container_name: logstash
  #   hostname: logstash
  #   networks:
  #     security_net:
  #       ipv4_address: 172.20.30.30
  #   environment:
  #     - "LS_JAVA_OPTS=-Xms1g -Xmx1g"
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #     - ELASTICSEARCH_USERNAME=elastic
  #     - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD:-changeme}
  #   volumes:
  #     - ./configs/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
  #     - ./configs/logstash/pipeline:/usr/share/logstash/pipeline:ro
  #   ports:
  #     - "5000:5000/tcp"   # JSON input
  #     - "5044:5044"       # Beats input
  #     - "9600:9600"       # Monitoring API
  #   depends_on:
  #     - elasticsearch
  #   restart: unless-stopped
  #   mem_limit: 1.5g
  #   cpus: 0.5

  # Suricata - IDS/IPS
  suricata:
    image: jasonish/suricata:latest
    container_name: suricata
    hostname: suricata
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_NICE
    volumes:
      - suricata_logs:/var/log/suricata
      - suricata_rules:/var/lib/suricata
      - ./configs/suricata/suricata.yaml:/etc/suricata/suricata.yaml
    command: -i eth0
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.0

  # TheHive - Incident Response Platform
  thehive:
    image: strangebee/thehive:5.2
    container_name: thehive
    hostname: thehive
    networks:
      security_net:
        ipv4_address: 172.20.30.40
    environment:
      - JVM_OPTS=-Xms1g -Xmx1g
    volumes:
      - thehive_data:/opt/thp/thehive/data
      - ./configs/thehive/application.conf:/etc/thehive/application.conf
    ports:
      - "9000:9000"
    depends_on:
      - elasticsearch
    restart: unless-stopped
    mem_limit: 1.5g
    cpus: 0.5

  # Cortex - TheHive Analysis Engine
  cortex:
    image: thehiveproject/cortex:latest
    container_name: cortex
    hostname: cortex
    networks:
      security_net:
        ipv4_address: 172.20.30.41
    environment:
      - job_directory=/tmp/cortex-jobs
    volumes:
      - cortex_data:/var/cortex
      - ./configs/cortex/application.conf:/etc/cortex/application.conf
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "9001:9001"
    depends_on:
      - elasticsearch
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.3

  # AI Log Analyzer - Custom Service
  # ai-analyzer:
  #   build:
  #     context: ./ai-analyzer
  #     dockerfile: Dockerfile
  #   container_name: ai-analyzer
  #   hostname: ai-analyzer
  #   networks:
  #     security_net:
  #       ipv4_address: 172.20.30.50
  #   environment:
  #     - ELASTICSEARCH_HOST=http://elasticsearch:9200
  #     - ELASTICSEARCH_USER=elastic
  #     - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD:-changeme}
  #     - OLLAMA_HOST=http://ollama:11434
  #     - WAZUH_API_URL=https://wazuh:55000
  #     - WAZUH_API_USER=wazuh-wui
  #     - WAZUH_API_PASSWORD=${WAZUH_API_PASSWORD:-MyS3cr37P450r.*-}
  #     - ALERT_WEBHOOK=${ROCKETCHAT_WEBHOOK_URL:-}
  #   volumes:
  #     - ./ai-analyzer:/app
  #     - ollama_data:/root/.ollama
  #   depends_on:
  #     - elasticsearch
  #     - wazuh
  #     - ollama
  #   restart: unless-stopped
  #   mem_limit: 2g
  #   cpus: 0.5

  # Ollama - Local LLM
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   hostname: ollama
  #   networks:
  #     security_net:
  #       ipv4_address: 172.20.30.51
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   restart: unless-stopped
  #   mem_limit: 4g
  #   cpus: 1.0

  # ============================================================================
  # MANAGEMENT NETWORK - MONITORING & ADMINISTRATION
  # ============================================================================

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    networks:
      management_net:
        ipv4_address: 172.20.40.10
      security_net:
        ipv4_address: 172.20.30.60
    volumes:
      - prometheus_data:/prometheus
      - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./configs/prometheus/alerts:/etc/prometheus/alerts:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
    ports:
      - "9090:9090"
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.3

  # Grafana - Monitoring Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    networks:
      management_net:
        ipv4_address: 172.20.40.11
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_AUTH_LDAP_ENABLED=true
      - GF_AUTH_LDAP_CONFIG_FILE=/etc/grafana/ldap.toml
    volumes:
      - grafana_data:/var/lib/grafana
      - ./configs/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./configs/grafana/ldap.toml:/etc/grafana/ldap.toml
      - ./dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - openldap
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.3

  # FreeRADIUS - AAA Server
  freeradius:
    image: freeradius/freeradius-server:latest
    container_name: freeradius
    hostname: freeradius
    networks:
      management_net:
        ipv4_address: 172.20.40.20
      internal_net:
        ipv4_address: 172.20.20.70
    environment:
      - RADIUS_LDAP_SERVER=openldap
      - RADIUS_LDAP_BASE_DN=dc=cyberlab,dc=local
      - RADIUS_LDAP_BIND_DN=cn=admin,dc=cyberlab,dc=local
      - RADIUS_LDAP_BIND_PASSWORD=${LDAP_ADMIN_PASSWORD:-admin}
    volumes:
      - radius_data:/etc/raddb
      - ./configs/radius:/config
    ports:
      - "1812:1812/udp" # Authentication
      - "1813:1813/udp" # Accounting
    depends_on:
      - openldap
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.2

  # Backup Service
  backup:
    image: restic/restic:latest
    container_name: backup
    hostname: backup
    networks:
      management_net:
        ipv4_address: 172.20.40.30
    environment:
      - RESTIC_REPOSITORY=/backup-repo
      - RESTIC_PASSWORD=${BACKUP_PASSWORD:-SecureBackupP@ss}
      - BACKUP_SCHEDULE=0 2 * * *
    volumes:
      - backup_data:/backup-repo
      - elasticsearch_data:/backup-source/elasticsearch:ro
      - postgres_data:/backup-source/postgres:ro
      - openldap_data:/backup-source/ldap:ro
      - wazuh_etc:/backup-source/wazuh:ro
      - ./configs:/backup-source/configs:ro
      - ./scripts/backup.sh:/usr/local/bin/backup.sh:ro
    command: sh -c "chmod +x /usr/local/bin/backup.sh && /usr/local/bin/backup.sh"
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.2

  # Node Exporter - System Metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    hostname: node-exporter
    networks:
      management_net:
        ipv4_address: 172.20.40.40
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    restart: unless-stopped
    mem_limit: 256m
    cpus: 0.1

  # cAdvisor - Container Metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    hostname: cadvisor
    networks:
      management_net:
        ipv4_address: 172.20.40.41
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /dev/disk:/dev/disk:ro
    ports:
      - "8081:8080"
    privileged: true
    devices:
      - /dev/kmsg
    restart: unless-stopped
    mem_limit: 256m
    cpus: 0.1
